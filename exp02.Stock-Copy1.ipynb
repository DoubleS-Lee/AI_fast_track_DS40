{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 주식 예측\n",
    "\n",
    "https://finance.yahoo.com/quote/005930.KS/history?period1=1441065600&period2=1598918400&interval=1d&filter=history&frequency=1d\n",
    "\n",
    "에서 5년치 주식 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1259 entries, 0 to 1258\n",
      "Data columns (total 7 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   Date       1259 non-null   object \n",
      " 1   Open       1259 non-null   float64\n",
      " 2   High       1259 non-null   float64\n",
      " 3   Low        1259 non-null   float64\n",
      " 4   Close      1259 non-null   float64\n",
      " 5   Adj Close  1259 non-null   float64\n",
      " 6   Volume     1259 non-null   int64  \n",
      "dtypes: float64(5), int64(1), object(1)\n",
      "memory usage: 69.0+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('./stock/AMZN.csv')\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of             Date         Open         High          Low        Close  \\\n",
       "0     2015-09-01   499.140015   510.000000   493.429993   496.540009   \n",
       "1     2015-09-02   505.089996   510.859985   497.720001   510.549988   \n",
       "2     2015-09-03   514.500000   515.840027   502.570007   504.720001   \n",
       "3     2015-09-04   497.649994   502.850006   495.640015   499.000000   \n",
       "4     2015-09-08   508.690002   518.349976   508.510010   517.539978   \n",
       "...          ...          ...          ...          ...          ...   \n",
       "1254  2020-08-25  3294.989990  3357.399902  3267.000000  3346.489990   \n",
       "1255  2020-08-26  3351.110107  3451.739990  3344.570068  3441.850098   \n",
       "1256  2020-08-27  3450.050049  3453.000000  3378.000000  3400.000000   \n",
       "1257  2020-08-28  3423.000000  3433.370117  3386.500000  3401.800049   \n",
       "1258  2020-08-31  3408.989990  3495.000000  3405.000000  3450.959961   \n",
       "\n",
       "        Adj Close   Volume  \n",
       "0      496.540009  3864500  \n",
       "1      510.549988  3707100  \n",
       "2      504.720001  3149700  \n",
       "3      499.000000  2692500  \n",
       "4      517.539978  3810700  \n",
       "...           ...      ...  \n",
       "1254  3346.489990  3992800  \n",
       "1255  3441.850098  6508700  \n",
       "1256  3400.000000  4264800  \n",
       "1257  3401.800049  2897000  \n",
       "1258  3450.959961  4175800  \n",
       "\n",
       "[1259 rows x 7 columns]>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 하루 주가의 대표값 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1259,)\n"
     ]
    }
   ],
   "source": [
    "high_prices = data['High'].values\n",
    "low_prices = data['Low'].values\n",
    "mid_prices = (high_prices + low_prices)/2\n",
    "\n",
    "print(mid_prices.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sequency data propcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "seq_len = 50\n",
    "\n",
    "def generateX(a, n):\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    for i in range(len(a)):\n",
    "        x = a[i:(i + n)]\n",
    "        if (i + n) < len(a):\n",
    "            x_train.append(x)\n",
    "            y_train.append(a[i + n])\n",
    "        else:\n",
    "            break\n",
    "    return np.array(x_train), np.array(y_train)\n",
    "\n",
    "\n",
    "# Sine 함수에 노이즈를 섞은 데이터로 학습 데이터 100개를 생성한다\n",
    "\n",
    "x, y = generateX(mid_prices, seq_len)\n",
    "x = x.reshape(-1,seq_len,1)\n",
    "y = y.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_num = 1000\n",
    "test_num = x.shape[0]-train_num\n",
    "\n",
    "x_train = x[:train_num, :, :]\n",
    "y_train = y[:train_num:, :]\n",
    "x_test = x[train_num:, :, :]\n",
    "y_test = y[train_num:, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 1743012.6250\n",
      "Epoch 2/500\n",
      "1000/1000 [==============================] - 0s 148us/sample - loss: 1742676.5000\n",
      "Epoch 3/500\n",
      "1000/1000 [==============================] - 0s 122us/sample - loss: 1742447.0000\n",
      "Epoch 4/500\n",
      "1000/1000 [==============================] - 0s 119us/sample - loss: 1742240.8750\n",
      "Epoch 5/500\n",
      "1000/1000 [==============================] - 0s 123us/sample - loss: 1742036.5000\n",
      "Epoch 6/500\n",
      "1000/1000 [==============================] - 0s 120us/sample - loss: 1741815.6250\n",
      "Epoch 7/500\n",
      "1000/1000 [==============================] - 0s 126us/sample - loss: 1741580.5000\n",
      "Epoch 8/500\n",
      "1000/1000 [==============================] - 0s 138us/sample - loss: 1741360.2500\n",
      "Epoch 9/500\n",
      "1000/1000 [==============================] - 0s 134us/sample - loss: 1741112.5000\n",
      "Epoch 10/500\n",
      "1000/1000 [==============================] - 0s 123us/sample - loss: 1740829.5000\n",
      "Epoch 11/500\n",
      "1000/1000 [==============================] - 0s 122us/sample - loss: 1740509.2500\n",
      "Epoch 12/500\n",
      "1000/1000 [==============================] - 0s 150us/sample - loss: 1740155.0000\n",
      "Epoch 13/500\n",
      "1000/1000 [==============================] - 0s 143us/sample - loss: 1739768.1250\n",
      "Epoch 14/500\n",
      "1000/1000 [==============================] - 0s 137us/sample - loss: 1739345.5000\n",
      "Epoch 15/500\n",
      "1000/1000 [==============================] - 0s 126us/sample - loss: 1738884.0000\n",
      "Epoch 16/500\n",
      "1000/1000 [==============================] - 0s 123us/sample - loss: 1738376.2500\n",
      "Epoch 17/500\n",
      "1000/1000 [==============================] - 0s 121us/sample - loss: 1737814.7500\n",
      "Epoch 18/500\n",
      "1000/1000 [==============================] - 0s 146us/sample - loss: 1737199.6250\n",
      "Epoch 19/500\n",
      "1000/1000 [==============================] - 0s 154us/sample - loss: 1736526.1250\n",
      "Epoch 20/500\n",
      "1000/1000 [==============================] - 0s 124us/sample - loss: 1735789.1250\n",
      "Epoch 21/500\n",
      "1000/1000 [==============================] - 0s 126us/sample - loss: 1734980.8750\n",
      "Epoch 22/500\n",
      "1000/1000 [==============================] - 0s 122us/sample - loss: 1734102.5000\n",
      "Epoch 23/500\n",
      "1000/1000 [==============================] - 0s 131us/sample - loss: 1733147.1250\n",
      "Epoch 24/500\n",
      "1000/1000 [==============================] - 0s 159us/sample - loss: 1732115.8750\n",
      "Epoch 25/500\n",
      "1000/1000 [==============================] - 0s 127us/sample - loss: 1731002.2500\n",
      "Epoch 26/500\n",
      "1000/1000 [==============================] - 0s 129us/sample - loss: 1729794.2500\n",
      "Epoch 27/500\n",
      "1000/1000 [==============================] - 0s 123us/sample - loss: 1728486.5000\n",
      "Epoch 28/500\n",
      "1000/1000 [==============================] - 0s 122us/sample - loss: 1727075.8750\n",
      "Epoch 29/500\n",
      "1000/1000 [==============================] - 0s 158us/sample - loss: 1725557.3750\n",
      "Epoch 30/500\n",
      "1000/1000 [==============================] - 0s 154us/sample - loss: 1723926.8750\n",
      "Epoch 31/500\n",
      "1000/1000 [==============================] - 0s 120us/sample - loss: 1722164.6250\n",
      "Epoch 32/500\n",
      "1000/1000 [==============================] - 0s 123us/sample - loss: 1720265.7500\n",
      "Epoch 33/500\n",
      "1000/1000 [==============================] - 0s 123us/sample - loss: 1718230.5000\n",
      "Epoch 34/500\n",
      "1000/1000 [==============================] - 0s 124us/sample - loss: 1716050.7500\n",
      "Epoch 35/500\n",
      "1000/1000 [==============================] - 0s 123us/sample - loss: 1713711.1250\n",
      "Epoch 36/500\n",
      "1000/1000 [==============================] - 0s 123us/sample - loss: 1711233.8750\n",
      "Epoch 37/500\n",
      "1000/1000 [==============================] - 0s 145us/sample - loss: 1708631.7500\n",
      "Epoch 38/500\n",
      "1000/1000 [==============================] - 0s 160us/sample - loss: 1705858.8750\n",
      "Epoch 39/500\n",
      "1000/1000 [==============================] - 0s 121us/sample - loss: 1702926.7500\n",
      "Epoch 40/500\n",
      "1000/1000 [==============================] - 0s 124us/sample - loss: 1699888.1250\n",
      "Epoch 41/500\n",
      "1000/1000 [==============================] - 0s 123us/sample - loss: 1696845.8750\n",
      "Epoch 42/500\n",
      "1000/1000 [==============================] - 0s 144us/sample - loss: 1693686.1250\n",
      "Epoch 43/500\n",
      "1000/1000 [==============================] - 0s 171us/sample - loss: 1690396.1250\n",
      "Epoch 44/500\n",
      "1000/1000 [==============================] - 0s 131us/sample - loss: 1686977.2500\n",
      "Epoch 45/500\n",
      "1000/1000 [==============================] - 0s 123us/sample - loss: 1683453.1250\n",
      "Epoch 46/500\n",
      "1000/1000 [==============================] - 0s 123us/sample - loss: 1679815.3750\n",
      "Epoch 47/500\n",
      "1000/1000 [==============================] - 0s 155us/sample - loss: 1676122.0000\n",
      "Epoch 48/500\n",
      "1000/1000 [==============================] - 0s 165us/sample - loss: 1672281.7500\n",
      "Epoch 49/500\n",
      "1000/1000 [==============================] - 0s 126us/sample - loss: 1668346.5000\n",
      "Epoch 50/500\n",
      "1000/1000 [==============================] - 0s 119us/sample - loss: 1664305.3750\n",
      "Epoch 51/500\n",
      "1000/1000 [==============================] - 0s 118us/sample - loss: 1660133.2500\n",
      "Epoch 52/500\n",
      "1000/1000 [==============================] - 0s 141us/sample - loss: 1655848.2500\n",
      "Epoch 53/500\n",
      "1000/1000 [==============================] - 0s 155us/sample - loss: 1651395.3750\n",
      "Epoch 54/500\n",
      "1000/1000 [==============================] - 0s 146us/sample - loss: 1646767.1250\n",
      "Epoch 55/500\n",
      "1000/1000 [==============================] - 0s 122us/sample - loss: 1641958.8750\n",
      "Epoch 56/500\n",
      "1000/1000 [==============================] - 0s 123us/sample - loss: 1636966.7500\n",
      "Epoch 57/500\n",
      "1000/1000 [==============================] - 0s 120us/sample - loss: 1631808.5000\n",
      "Epoch 58/500\n",
      "1000/1000 [==============================] - 0s 122us/sample - loss: 1626531.7500\n",
      "Epoch 59/500\n",
      "1000/1000 [==============================] - 0s 135us/sample - loss: 1621070.2500\n",
      "Epoch 60/500\n",
      "1000/1000 [==============================] - 0s 141us/sample - loss: 1615438.5000\n",
      "Epoch 61/500\n",
      "1000/1000 [==============================] - 0s 138us/sample - loss: 1609587.7500\n",
      "Epoch 62/500\n",
      "1000/1000 [==============================] - 0s 138us/sample - loss: 1603534.3750\n",
      "Epoch 63/500\n",
      "1000/1000 [==============================] - 0s 144us/sample - loss: 1597272.8750\n",
      "Epoch 64/500\n",
      "1000/1000 [==============================] - 0s 127us/sample - loss: 1590835.8750\n",
      "Epoch 65/500\n",
      "1000/1000 [==============================] - 0s 150us/sample - loss: 1584177.1250\n",
      "Epoch 66/500\n",
      "1000/1000 [==============================] - 0s 133us/sample - loss: 1577307.6250\n",
      "Epoch 67/500\n",
      "1000/1000 [==============================] - 0s 134us/sample - loss: 1570281.0000\n",
      "Epoch 68/500\n",
      "1000/1000 [==============================] - 0s 134us/sample - loss: 1563044.8750\n",
      "Epoch 69/500\n",
      "1000/1000 [==============================] - 0s 140us/sample - loss: 1555597.7500\n",
      "Epoch 70/500\n",
      "1000/1000 [==============================] - 0s 139us/sample - loss: 1547937.8750\n",
      "Epoch 71/500\n",
      "1000/1000 [==============================] - 0s 135us/sample - loss: 1540064.6250\n",
      "Epoch 72/500\n",
      "1000/1000 [==============================] - 0s 134us/sample - loss: 1531976.1250\n",
      "Epoch 73/500\n",
      "1000/1000 [==============================] - 0s 129us/sample - loss: 1523670.5000\n",
      "Epoch 74/500\n",
      "1000/1000 [==============================] - 0s 116us/sample - loss: 1515147.1250\n",
      "Epoch 75/500\n",
      "1000/1000 [==============================] - 0s 121us/sample - loss: 1506404.2500\n",
      "Epoch 76/500\n",
      "1000/1000 [==============================] - 0s 124us/sample - loss: 1497440.8750\n",
      "Epoch 77/500\n",
      "1000/1000 [==============================] - 0s 139us/sample - loss: 1488256.2500\n",
      "Epoch 78/500\n",
      "1000/1000 [==============================] - 0s 135us/sample - loss: 1478849.0000\n",
      "Epoch 79/500\n",
      "1000/1000 [==============================] - 0s 139us/sample - loss: 1469219.5000\n",
      "Epoch 80/500\n",
      "1000/1000 [==============================] - 0s 141us/sample - loss: 1459365.8750\n",
      "Epoch 81/500\n",
      "1000/1000 [==============================] - 0s 130us/sample - loss: 1449289.0000\n",
      "Epoch 82/500\n",
      "1000/1000 [==============================] - 0s 135us/sample - loss: 1438987.5000\n",
      "Epoch 83/500\n",
      "1000/1000 [==============================] - 0s 139us/sample - loss: 1428462.3750\n",
      "Epoch 84/500\n",
      "1000/1000 [==============================] - 0s 141us/sample - loss: 1417713.6250\n",
      "Epoch 85/500\n",
      "1000/1000 [==============================] - 0s 140us/sample - loss: 1406741.6250\n",
      "Epoch 86/500\n",
      "1000/1000 [==============================] - 0s 142us/sample - loss: 1395546.8750\n",
      "Epoch 87/500\n",
      "1000/1000 [==============================] - 0s 134us/sample - loss: 1384130.1250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/500\n",
      "1000/1000 [==============================] - 0s 136us/sample - loss: 1372497.6250\n",
      "Epoch 89/500\n",
      "1000/1000 [==============================] - 0s 131us/sample - loss: 1360637.6250\n",
      "Epoch 90/500\n",
      "1000/1000 [==============================] - 0s 140us/sample - loss: 1348563.7500\n",
      "Epoch 91/500\n",
      "1000/1000 [==============================] - 0s 128us/sample - loss: 1336274.1250\n",
      "Epoch 92/500\n",
      "1000/1000 [==============================] - 0s 137us/sample - loss: 1323770.7500\n",
      "Epoch 93/500\n",
      "1000/1000 [==============================] - 0s 140us/sample - loss: 1311055.8750\n",
      "Epoch 94/500\n",
      "1000/1000 [==============================] - 0s 140us/sample - loss: 1298132.2500\n",
      "Epoch 95/500\n",
      "1000/1000 [==============================] - 0s 138us/sample - loss: 1285002.6250\n",
      "Epoch 96/500\n",
      "1000/1000 [==============================] - 0s 132us/sample - loss: 1271670.3750\n",
      "Epoch 97/500\n",
      "1000/1000 [==============================] - 0s 131us/sample - loss: 1258138.5000\n",
      "Epoch 98/500\n",
      "1000/1000 [==============================] - 0s 136us/sample - loss: 1244411.2500\n",
      "Epoch 99/500\n",
      "1000/1000 [==============================] - 0s 137us/sample - loss: 1230492.3750\n",
      "Epoch 100/500\n",
      "1000/1000 [==============================] - 0s 131us/sample - loss: 1216386.3750\n",
      "Epoch 101/500\n",
      "1000/1000 [==============================] - 0s 130us/sample - loss: 1202097.6250\n",
      "Epoch 102/500\n",
      "1000/1000 [==============================] - 0s 134us/sample - loss: 1187631.3750\n",
      "Epoch 103/500\n",
      "1000/1000 [==============================] - 0s 138us/sample - loss: 1172992.5000\n",
      "Epoch 104/500\n",
      "1000/1000 [==============================] - 0s 133us/sample - loss: 1158186.7500\n",
      "Epoch 105/500\n",
      "1000/1000 [==============================] - 0s 132us/sample - loss: 1143219.7500\n",
      "Epoch 106/500\n",
      "1000/1000 [==============================] - 0s 129us/sample - loss: 1128097.8750\n",
      "Epoch 107/500\n",
      "1000/1000 [==============================] - 0s 133us/sample - loss: 1112827.5000\n",
      "Epoch 108/500\n",
      "1000/1000 [==============================] - 0s 131us/sample - loss: 1097415.2500\n",
      "Epoch 109/500\n",
      "1000/1000 [==============================] - 0s 129us/sample - loss: 1081868.3750\n",
      "Epoch 110/500\n",
      "1000/1000 [==============================] - 0s 133us/sample - loss: 1066159.0000\n",
      "Epoch 111/500\n",
      "1000/1000 [==============================] - 0s 130us/sample - loss: 1050316.3750\n",
      "Epoch 112/500\n",
      "1000/1000 [==============================] - 0s 135us/sample - loss: 1034351.8125\n",
      "Epoch 113/500\n",
      "1000/1000 [==============================] - 0s 138us/sample - loss: 1018274.8125\n",
      "Epoch 114/500\n",
      "1000/1000 [==============================] - 0s 134us/sample - loss: 1002094.9375\n",
      "Epoch 115/500\n",
      "1000/1000 [==============================] - 0s 134us/sample - loss: 985821.2500\n",
      "Epoch 116/500\n",
      "1000/1000 [==============================] - 0s 128us/sample - loss: 969463.5000\n",
      "Epoch 117/500\n",
      "1000/1000 [==============================] - 0s 134us/sample - loss: 953031.6875\n",
      "Epoch 118/500\n",
      "1000/1000 [==============================] - 0s 136us/sample - loss: 936535.6250\n",
      "Epoch 119/500\n",
      "1000/1000 [==============================] - 0s 131us/sample - loss: 919985.8750\n",
      "Epoch 120/500\n",
      "1000/1000 [==============================] - 0s 134us/sample - loss: 903392.7500\n",
      "Epoch 121/500\n",
      "1000/1000 [==============================] - 0s 131us/sample - loss: 886767.5000\n",
      "Epoch 122/500\n",
      "1000/1000 [==============================] - 0s 139us/sample - loss: 870121.0625\n",
      "Epoch 123/500\n",
      "1000/1000 [==============================] - 0s 132us/sample - loss: 853465.0000\n",
      "Epoch 124/500\n",
      "1000/1000 [==============================] - 0s 139us/sample - loss: 836810.8125\n",
      "Epoch 125/500\n",
      "1000/1000 [==============================] - 0s 135us/sample - loss: 820170.4375\n",
      "Epoch 126/500\n",
      "1000/1000 [==============================] - 0s 129us/sample - loss: 803556.2500\n",
      "Epoch 127/500\n",
      "1000/1000 [==============================] - 0s 135us/sample - loss: 786980.1875\n",
      "Epoch 128/500\n",
      "1000/1000 [==============================] - 0s 141us/sample - loss: 770455.0625\n",
      "Epoch 129/500\n",
      "1000/1000 [==============================] - 0s 134us/sample - loss: 753993.2500\n",
      "Epoch 130/500\n",
      "1000/1000 [==============================] - 0s 136us/sample - loss: 737608.0000\n",
      "Epoch 131/500\n",
      "1000/1000 [==============================] - 0s 133us/sample - loss: 721311.9375\n",
      "Epoch 132/500\n",
      "1000/1000 [==============================] - 0s 132us/sample - loss: 705118.0000\n",
      "Epoch 133/500\n",
      "1000/1000 [==============================] - 0s 136us/sample - loss: 689039.5000\n",
      "Epoch 134/500\n",
      "1000/1000 [==============================] - 0s 134us/sample - loss: 673089.5000\n",
      "Epoch 135/500\n",
      "1000/1000 [==============================] - 0s 135us/sample - loss: 657281.3750\n",
      "Epoch 136/500\n",
      "1000/1000 [==============================] - 0s 134us/sample - loss: 641627.9375\n",
      "Epoch 137/500\n",
      "1000/1000 [==============================] - 0s 135us/sample - loss: 626142.5000\n",
      "Epoch 138/500\n",
      "1000/1000 [==============================] - 0s 137us/sample - loss: 610838.0000\n",
      "Epoch 139/500\n",
      "1000/1000 [==============================] - 0s 137us/sample - loss: 595727.4375\n",
      "Epoch 140/500\n",
      "1000/1000 [==============================] - 0s 138us/sample - loss: 580823.5000\n",
      "Epoch 141/500\n",
      "1000/1000 [==============================] - 0s 135us/sample - loss: 566138.6250\n",
      "Epoch 142/500\n",
      "1000/1000 [==============================] - 0s 131us/sample - loss: 551685.3750\n",
      "Epoch 143/500\n",
      "1000/1000 [==============================] - 0s 129us/sample - loss: 537475.5625\n",
      "Epoch 144/500\n",
      "1000/1000 [==============================] - 0s 131us/sample - loss: 523521.2500\n",
      "Epoch 145/500\n",
      "1000/1000 [==============================] - 0s 134us/sample - loss: 509833.7812\n",
      "Epoch 146/500\n",
      "1000/1000 [==============================] - 0s 133us/sample - loss: 496424.0000\n",
      "Epoch 147/500\n",
      "1000/1000 [==============================] - 0s 138us/sample - loss: 483302.5938\n",
      "Epoch 148/500\n",
      "1000/1000 [==============================] - 0s 134us/sample - loss: 470479.8438\n",
      "Epoch 149/500\n",
      "1000/1000 [==============================] - 0s 133us/sample - loss: 457965.3125\n",
      "Epoch 150/500\n",
      "1000/1000 [==============================] - 0s 136us/sample - loss: 445768.0938\n",
      "Epoch 151/500\n",
      "1000/1000 [==============================] - 0s 136us/sample - loss: 433896.5312\n",
      "Epoch 152/500\n",
      "1000/1000 [==============================] - 0s 136us/sample - loss: 422358.5938\n",
      "Epoch 153/500\n",
      "1000/1000 [==============================] - 0s 129us/sample - loss: 411161.5625\n",
      "Epoch 154/500\n",
      "1000/1000 [==============================] - 0s 144us/sample - loss: 400311.7188\n",
      "Epoch 155/500\n",
      "1000/1000 [==============================] - 0s 131us/sample - loss: 389814.7812\n",
      "Epoch 156/500\n",
      "1000/1000 [==============================] - 0s 135us/sample - loss: 379675.8750\n",
      "Epoch 157/500\n",
      "1000/1000 [==============================] - 0s 135us/sample - loss: 369899.0625\n",
      "Epoch 158/500\n",
      "1000/1000 [==============================] - 0s 138us/sample - loss: 360487.5312\n",
      "Epoch 159/500\n",
      "1000/1000 [==============================] - 0s 133us/sample - loss: 351443.9688\n",
      "Epoch 160/500\n",
      "1000/1000 [==============================] - 0s 133us/sample - loss: 342769.6562\n",
      "Epoch 161/500\n",
      "1000/1000 [==============================] - 0s 120us/sample - loss: 334465.4062\n",
      "Epoch 162/500\n",
      "1000/1000 [==============================] - 0s 140us/sample - loss: 326530.9062\n",
      "Epoch 163/500\n",
      "1000/1000 [==============================] - 0s 135us/sample - loss: 318965.1562\n",
      "Epoch 164/500\n",
      "1000/1000 [==============================] - 0s 122us/sample - loss: 311765.8750\n",
      "Epoch 165/500\n",
      "1000/1000 [==============================] - 0s 133us/sample - loss: 304930.0625\n",
      "Epoch 166/500\n",
      "1000/1000 [==============================] - 0s 129us/sample - loss: 298453.9688\n",
      "Epoch 167/500\n",
      "1000/1000 [==============================] - 0s 129us/sample - loss: 292332.5625\n",
      "Epoch 168/500\n",
      "1000/1000 [==============================] - 0s 131us/sample - loss: 286560.4062\n",
      "Epoch 169/500\n",
      "1000/1000 [==============================] - 0s 129us/sample - loss: 281130.8125\n",
      "Epoch 170/500\n",
      "1000/1000 [==============================] - 0s 131us/sample - loss: 276036.5625\n",
      "Epoch 171/500\n",
      "1000/1000 [==============================] - 0s 136us/sample - loss: 271269.2812\n",
      "Epoch 172/500\n",
      "1000/1000 [==============================] - 0s 135us/sample - loss: 266820.5000\n",
      "Epoch 173/500\n",
      "1000/1000 [==============================] - 0s 130us/sample - loss: 262680.5000\n",
      "Epoch 174/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 127us/sample - loss: 258839.1406\n",
      "Epoch 175/500\n",
      "1000/1000 [==============================] - 0s 138us/sample - loss: 255285.6875\n",
      "Epoch 176/500\n",
      "1000/1000 [==============================] - 0s 131us/sample - loss: 252008.9844\n",
      "Epoch 177/500\n",
      "1000/1000 [==============================] - 0s 135us/sample - loss: 248997.3281\n",
      "Epoch 178/500\n",
      "1000/1000 [==============================] - 0s 141us/sample - loss: 246238.7500\n",
      "Epoch 179/500\n",
      "1000/1000 [==============================] - 0s 128us/sample - loss: 243721.0469\n",
      "Epoch 180/500\n",
      "1000/1000 [==============================] - 0s 122us/sample - loss: 241431.5156\n",
      "Epoch 181/500\n",
      "1000/1000 [==============================] - 0s 127us/sample - loss: 239357.6406\n",
      "Epoch 182/500\n",
      "1000/1000 [==============================] - 0s 126us/sample - loss: 237486.7500\n",
      "Epoch 183/500\n",
      "1000/1000 [==============================] - 0s 126us/sample - loss: 235805.9844\n",
      "Epoch 184/500\n",
      "1000/1000 [==============================] - 0s 134us/sample - loss: 234302.8906\n",
      "Epoch 185/500\n",
      "1000/1000 [==============================] - 0s 133us/sample - loss: 232964.9531\n",
      "Epoch 186/500\n",
      "1000/1000 [==============================] - 0s 126us/sample - loss: 231779.9219\n",
      "Epoch 187/500\n",
      "1000/1000 [==============================] - 0s 125us/sample - loss: 230735.9062\n",
      "Epoch 188/500\n",
      "1000/1000 [==============================] - 0s 126us/sample - loss: 229821.2031\n",
      "Epoch 189/500\n",
      "1000/1000 [==============================] - 0s 131us/sample - loss: 229024.7031\n",
      "Epoch 190/500\n",
      "1000/1000 [==============================] - 0s 134us/sample - loss: 228335.5312\n",
      "Epoch 191/500\n",
      "1000/1000 [==============================] - 0s 126us/sample - loss: 227743.4688\n",
      "Epoch 192/500\n",
      "1000/1000 [==============================] - 0s 127us/sample - loss: 227238.6562\n",
      "Epoch 193/500\n",
      "1000/1000 [==============================] - 0s 126us/sample - loss: 226811.9062\n",
      "Epoch 194/500\n",
      "1000/1000 [==============================] - 0s 130us/sample - loss: 226454.4688\n",
      "Epoch 195/500\n",
      "1000/1000 [==============================] - 0s 136us/sample - loss: 226158.2344\n",
      "Epoch 196/500\n",
      "1000/1000 [==============================] - 0s 124us/sample - loss: 225915.7188\n",
      "Epoch 197/500\n",
      "1000/1000 [==============================] - 0s 146us/sample - loss: 225719.8906\n",
      "Epoch 198/500\n",
      "1000/1000 [==============================] - 0s 130us/sample - loss: 225564.3906\n",
      "Epoch 199/500\n",
      "1000/1000 [==============================] - 0s 124us/sample - loss: 225443.4062\n",
      "Epoch 200/500\n",
      "1000/1000 [==============================] - 0s 130us/sample - loss: 225351.6406\n",
      "Epoch 201/500\n",
      "1000/1000 [==============================] - 0s 126us/sample - loss: 225284.4062\n",
      "Epoch 202/500\n",
      "1000/1000 [==============================] - 0s 127us/sample - loss: 225237.3906\n",
      "Epoch 203/500\n",
      "1000/1000 [==============================] - 0s 129us/sample - loss: 225206.8594\n",
      "Epoch 204/500\n",
      "1000/1000 [==============================] - 0s 127us/sample - loss: 225189.6094\n",
      "Epoch 205/500\n",
      "1000/1000 [==============================] - 0s 116us/sample - loss: 225182.6875\n",
      "Epoch 206/500\n",
      "1000/1000 [==============================] - 0s 133us/sample - loss: 225183.6406\n",
      "Epoch 207/500\n",
      "1000/1000 [==============================] - 0s 125us/sample - loss: 225190.3906\n",
      "Epoch 208/500\n",
      "1000/1000 [==============================] - 0s 127us/sample - loss: 225201.1250\n",
      "Epoch 209/500\n",
      "1000/1000 [==============================] - 0s 125us/sample - loss: 225214.3750\n",
      "Epoch 210/500\n",
      "1000/1000 [==============================] - 0s 128us/sample - loss: 225228.9219\n",
      "Epoch 211/500\n",
      "1000/1000 [==============================] - 0s 134us/sample - loss: 225243.8281\n",
      "Epoch 212/500\n",
      "1000/1000 [==============================] - 0s 127us/sample - loss: 225258.3438\n",
      "Epoch 213/500\n",
      "1000/1000 [==============================] - 0s 129us/sample - loss: 225271.8594\n",
      "Epoch 214/500\n",
      "1000/1000 [==============================] - 0s 132us/sample - loss: 225283.9531\n",
      "Epoch 215/500\n",
      "1000/1000 [==============================] - 0s 130us/sample - loss: 225294.4062\n",
      "Epoch 216/500\n",
      "1000/1000 [==============================] - 0s 126us/sample - loss: 225303.0156\n",
      "Epoch 217/500\n",
      "1000/1000 [==============================] - 0s 131us/sample - loss: 225309.6875\n",
      "Epoch 218/500\n",
      "1000/1000 [==============================] - 0s 131us/sample - loss: 225314.4375\n",
      "Epoch 219/500\n",
      "1000/1000 [==============================] - 0s 131us/sample - loss: 225317.3438\n",
      "Epoch 220/500\n",
      "1000/1000 [==============================] - 0s 126us/sample - loss: 225318.5000\n",
      "Epoch 221/500\n",
      "1000/1000 [==============================] - 0s 128us/sample - loss: 225318.0625\n",
      "Epoch 222/500\n",
      "1000/1000 [==============================] - 0s 130us/sample - loss: 225316.1562\n",
      "Epoch 223/500\n",
      "1000/1000 [==============================] - 0s 125us/sample - loss: 225312.9844\n",
      "Epoch 224/500\n",
      "1000/1000 [==============================] - 0s 130us/sample - loss: 225308.7344\n",
      "Epoch 225/500\n",
      "1000/1000 [==============================] - 0s 123us/sample - loss: 225303.5938\n",
      "Epoch 226/500\n",
      "1000/1000 [==============================] - 0s 123us/sample - loss: 225297.7188\n",
      "Epoch 227/500\n",
      "1000/1000 [==============================] - 0s 131us/sample - loss: 225291.3125\n",
      "Epoch 228/500\n",
      "1000/1000 [==============================] - 0s 126us/sample - loss: 225284.4844\n",
      "Epoch 229/500\n",
      "1000/1000 [==============================] - 0s 126us/sample - loss: 225277.3906\n",
      "Epoch 230/500\n",
      "1000/1000 [==============================] - 0s 126us/sample - loss: 225270.2188\n",
      "Epoch 231/500\n",
      "1000/1000 [==============================] - 0s 131us/sample - loss: 225263.0469\n",
      "Epoch 232/500\n",
      "1000/1000 [==============================] - 0s 138us/sample - loss: 225255.9531\n",
      "Epoch 233/500\n",
      "1000/1000 [==============================] - 0s 127us/sample - loss: 225249.0312\n",
      "Epoch 234/500\n",
      "1000/1000 [==============================] - 0s 130us/sample - loss: 225242.3906\n",
      "Epoch 235/500\n",
      "1000/1000 [==============================] - 0s 129us/sample - loss: 225236.0000\n",
      "Epoch 236/500\n",
      "1000/1000 [==============================] - 0s 134us/sample - loss: 225230.0000\n",
      "Epoch 237/500\n",
      "1000/1000 [==============================] - 0s 128us/sample - loss: 225224.3906\n",
      "Epoch 238/500\n",
      "1000/1000 [==============================] - 0s 135us/sample - loss: 225219.1719\n",
      "Epoch 239/500\n",
      "1000/1000 [==============================] - 0s 134us/sample - loss: 225214.3750\n",
      "Epoch 240/500\n",
      "1000/1000 [==============================] - 0s 128us/sample - loss: 225209.9688\n",
      "Epoch 241/500\n",
      "1000/1000 [==============================] - 0s 129us/sample - loss: 225205.9844\n",
      "Epoch 242/500\n",
      "1000/1000 [==============================] - 0s 129us/sample - loss: 225202.4219\n",
      "Epoch 243/500\n",
      "1000/1000 [==============================] - 0s 124us/sample - loss: 225199.2500\n",
      "Epoch 244/500\n",
      "1000/1000 [==============================] - 0s 125us/sample - loss: 225196.4219\n",
      "Epoch 245/500\n",
      "1000/1000 [==============================] - 0s 127us/sample - loss: 225193.9531\n",
      "Epoch 246/500\n",
      "1000/1000 [==============================] - 0s 118us/sample - loss: 225191.7969\n",
      "Epoch 247/500\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 225189.9219\n",
      "Epoch 248/500\n",
      "1000/1000 [==============================] - 0s 117us/sample - loss: 225188.3906\n",
      "Epoch 249/500\n",
      "1000/1000 [==============================] - 0s 121us/sample - loss: 225187.0469\n",
      "Epoch 250/500\n",
      "1000/1000 [==============================] - 0s 133us/sample - loss: 225185.9375\n",
      "Epoch 251/500\n",
      "1000/1000 [==============================] - 0s 133us/sample - loss: 225185.0156\n",
      "Epoch 252/500\n",
      "1000/1000 [==============================] - 0s 123us/sample - loss: 225184.2656\n",
      "Epoch 253/500\n",
      "1000/1000 [==============================] - 0s 129us/sample - loss: 225183.7031\n",
      "Epoch 254/500\n",
      "1000/1000 [==============================] - 0s 130us/sample - loss: 225183.2188\n",
      "Epoch 255/500\n",
      "1000/1000 [==============================] - 0s 124us/sample - loss: 225182.8906\n",
      "Epoch 256/500\n",
      "1000/1000 [==============================] - 0s 126us/sample - loss: 225182.6250\n",
      "Epoch 257/500\n",
      "1000/1000 [==============================] - 0s 129us/sample - loss: 225182.4531\n",
      "Epoch 258/500\n",
      "1000/1000 [==============================] - 0s 126us/sample - loss: 225182.3438\n",
      "Epoch 259/500\n",
      "1000/1000 [==============================] - 0s 137us/sample - loss: 225182.2812\n",
      "Epoch 260/500\n",
      "1000/1000 [==============================] - 0s 133us/sample - loss: 225182.2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 261/500\n",
      "1000/1000 [==============================] - 0s 129us/sample - loss: 225182.2500\n",
      "Epoch 262/500\n",
      "1000/1000 [==============================] - 0s 133us/sample - loss: 225182.2812\n",
      "Epoch 263/500\n",
      "1000/1000 [==============================] - 0s 128us/sample - loss: 225182.3594\n",
      "Epoch 264/500\n",
      "1000/1000 [==============================] - 0s 132us/sample - loss: 225182.3906\n",
      "Epoch 265/500\n",
      "1000/1000 [==============================] - 0s 123us/sample - loss: 225182.4375\n",
      "Epoch 266/500\n",
      "1000/1000 [==============================] - 0s 128us/sample - loss: 225182.5000\n",
      "Epoch 267/500\n",
      "1000/1000 [==============================] - 0s 130us/sample - loss: 225182.5625\n",
      "Epoch 268/500\n",
      "1000/1000 [==============================] - 0s 126us/sample - loss: 225182.6250\n",
      "Epoch 269/500\n",
      "1000/1000 [==============================] - 0s 124us/sample - loss: 225182.6406\n",
      "Epoch 270/500\n",
      "1000/1000 [==============================] - 0s 132us/sample - loss: 225182.6875\n",
      "Epoch 271/500\n",
      "1000/1000 [==============================] - 0s 131us/sample - loss: 225182.7188\n",
      "Epoch 272/500\n",
      "1000/1000 [==============================] - 0s 131us/sample - loss: 225182.7188\n",
      "Epoch 273/500\n",
      "1000/1000 [==============================] - 0s 132us/sample - loss: 225182.7344\n",
      "Epoch 274/500\n",
      "1000/1000 [==============================] - 0s 128us/sample - loss: 225182.7656\n",
      "Epoch 275/500\n",
      "1000/1000 [==============================] - 0s 127us/sample - loss: 225182.7344\n",
      "Epoch 276/500\n",
      "1000/1000 [==============================] - 0s 122us/sample - loss: 225182.7344\n",
      "Epoch 277/500\n",
      "1000/1000 [==============================] - 0s 133us/sample - loss: 225182.7500\n",
      "Epoch 278/500\n",
      "1000/1000 [==============================] - 0s 129us/sample - loss: 225182.7031\n",
      "Epoch 279/500\n",
      "1000/1000 [==============================] - 0s 132us/sample - loss: 225182.6875\n",
      "Epoch 280/500\n",
      "1000/1000 [==============================] - 0s 127us/sample - loss: 225182.6875\n",
      "Epoch 281/500\n",
      "1000/1000 [==============================] - 0s 123us/sample - loss: 225182.6562\n",
      "Epoch 282/500\n",
      "1000/1000 [==============================] - 0s 130us/sample - loss: 225182.6250\n",
      "Epoch 283/500\n",
      "1000/1000 [==============================] - 0s 125us/sample - loss: 225182.5938\n",
      "Epoch 284/500\n",
      "1000/1000 [==============================] - 0s 132us/sample - loss: 225182.5625\n",
      "Epoch 285/500\n",
      "1000/1000 [==============================] - 0s 132us/sample - loss: 225182.5312\n",
      "Epoch 286/500\n",
      "1000/1000 [==============================] - 0s 128us/sample - loss: 225182.5000\n",
      "Epoch 287/500\n",
      "1000/1000 [==============================] - 0s 128us/sample - loss: 225182.4844\n",
      "Epoch 288/500\n",
      "1000/1000 [==============================] - 0s 132us/sample - loss: 225182.4531\n",
      "Epoch 289/500\n",
      "1000/1000 [==============================] - 0s 127us/sample - loss: 225182.4531\n",
      "Epoch 290/500\n",
      "1000/1000 [==============================] - 0s 128us/sample - loss: 225182.4062\n",
      "Epoch 291/500\n",
      "1000/1000 [==============================] - 0s 129us/sample - loss: 225182.4062\n",
      "Epoch 292/500\n",
      "1000/1000 [==============================] - 0s 124us/sample - loss: 225182.3594\n",
      "Epoch 293/500\n",
      "1000/1000 [==============================] - 0s 129us/sample - loss: 225182.3750\n",
      "Epoch 294/500\n",
      "1000/1000 [==============================] - 0s 130us/sample - loss: 225182.3438\n",
      "Epoch 295/500\n",
      "1000/1000 [==============================] - 0s 134us/sample - loss: 225182.3438\n",
      "Epoch 296/500\n",
      "1000/1000 [==============================] - 0s 130us/sample - loss: 225182.2969\n",
      "Epoch 297/500\n",
      "1000/1000 [==============================] - 0s 133us/sample - loss: 225182.3125\n",
      "Epoch 298/500\n",
      "1000/1000 [==============================] - 0s 130us/sample - loss: 225182.2969\n",
      "Epoch 299/500\n",
      "1000/1000 [==============================] - 0s 137us/sample - loss: 225182.2656\n",
      "Epoch 300/500\n",
      "1000/1000 [==============================] - 0s 128us/sample - loss: 225182.2812\n",
      "Epoch 301/500\n",
      "1000/1000 [==============================] - 0s 130us/sample - loss: 225182.2656\n",
      "Epoch 302/500\n",
      "1000/1000 [==============================] - 0s 131us/sample - loss: 225182.2656\n",
      "Epoch 303/500\n",
      "1000/1000 [==============================] - 0s 125us/sample - loss: 225182.2656\n",
      "Epoch 304/500\n",
      "1000/1000 [==============================] - 0s 128us/sample - loss: 225182.2344\n",
      "Epoch 305/500\n",
      "1000/1000 [==============================] - 0s 130us/sample - loss: 225182.2188\n",
      "Epoch 306/500\n",
      "1000/1000 [==============================] - 0s 134us/sample - loss: 225182.2500\n",
      "Epoch 307/500\n",
      "1000/1000 [==============================] - 0s 128us/sample - loss: 225182.2500\n",
      "Epoch 308/500\n",
      "1000/1000 [==============================] - 0s 127us/sample - loss: 225182.2344\n",
      "Epoch 309/500\n",
      "1000/1000 [==============================] - 0s 128us/sample - loss: 225182.2344\n",
      "Epoch 310/500\n",
      "1000/1000 [==============================] - 0s 126us/sample - loss: 225182.2344\n",
      "Epoch 311/500\n",
      "1000/1000 [==============================] - 0s 130us/sample - loss: 225182.2500\n",
      "Epoch 312/500\n",
      "1000/1000 [==============================] - 0s 129us/sample - loss: 225182.2344\n",
      "Epoch 313/500\n",
      "1000/1000 [==============================] - 0s 125us/sample - loss: 225182.2344\n",
      "Epoch 314/500\n",
      "1000/1000 [==============================] - 0s 123us/sample - loss: 225182.2500\n",
      "Epoch 315/500\n",
      "1000/1000 [==============================] - 0s 127us/sample - loss: 225182.2344\n",
      "Epoch 316/500\n",
      "1000/1000 [==============================] - 0s 128us/sample - loss: 225182.2500\n",
      "Epoch 317/500\n",
      "1000/1000 [==============================] - 0s 128us/sample - loss: 225182.2500\n",
      "Epoch 318/500\n",
      "1000/1000 [==============================] - 0s 127us/sample - loss: 225182.2500\n",
      "Epoch 319/500\n",
      "1000/1000 [==============================] - 0s 132us/sample - loss: 225182.2656\n",
      "Epoch 320/500\n",
      "1000/1000 [==============================] - 0s 123us/sample - loss: 225182.2344\n",
      "Epoch 321/500\n",
      "1000/1000 [==============================] - 0s 129us/sample - loss: 225182.2656\n",
      "Epoch 322/500\n",
      "1000/1000 [==============================] - 0s 125us/sample - loss: 225182.2344\n",
      "Epoch 323/500\n",
      "1000/1000 [==============================] - 0s 126us/sample - loss: 225182.2344\n",
      "Epoch 324/500\n",
      "1000/1000 [==============================] - 0s 127us/sample - loss: 225182.2500\n",
      "Epoch 325/500\n",
      "1000/1000 [==============================] - 0s 124us/sample - loss: 225182.2500\n",
      "Epoch 326/500\n",
      "1000/1000 [==============================] - 0s 116us/sample - loss: 225182.2500\n",
      "Epoch 327/500\n",
      "1000/1000 [==============================] - 0s 119us/sample - loss: 225182.2656\n",
      "Epoch 328/500\n",
      "1000/1000 [==============================] - 0s 120us/sample - loss: 225182.2344\n",
      "Epoch 329/500\n",
      "1000/1000 [==============================] - 0s 122us/sample - loss: 225182.2500\n",
      "Epoch 330/500\n",
      "1000/1000 [==============================] - 0s 118us/sample - loss: 225182.2344\n",
      "Epoch 331/500\n",
      "1000/1000 [==============================] - 0s 119us/sample - loss: 225182.2656\n",
      "Epoch 332/500\n",
      "1000/1000 [==============================] - 0s 123us/sample - loss: 225182.2500\n",
      "Epoch 333/500\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 225182.2344\n",
      "Epoch 334/500\n",
      "1000/1000 [==============================] - 0s 131us/sample - loss: 225182.2344\n",
      "Epoch 335/500\n",
      "1000/1000 [==============================] - 0s 122us/sample - loss: 225182.2500\n",
      "Epoch 336/500\n",
      "1000/1000 [==============================] - 0s 117us/sample - loss: 225182.2344\n",
      "Epoch 337/500\n",
      "1000/1000 [==============================] - 0s 126us/sample - loss: 225182.2500\n",
      "Epoch 338/500\n",
      "1000/1000 [==============================] - 0s 128us/sample - loss: 225182.2500\n",
      "Epoch 339/500\n",
      "1000/1000 [==============================] - 0s 128us/sample - loss: 225182.2344\n",
      "Epoch 340/500\n",
      "1000/1000 [==============================] - 0s 132us/sample - loss: 225182.2500\n",
      "Epoch 341/500\n",
      "1000/1000 [==============================] - 0s 135us/sample - loss: 225182.2344\n",
      "Epoch 342/500\n",
      "1000/1000 [==============================] - 0s 129us/sample - loss: 225182.2344\n",
      "Epoch 343/500\n",
      "1000/1000 [==============================] - 0s 131us/sample - loss: 225182.2500\n",
      "Epoch 344/500\n",
      "1000/1000 [==============================] - 0s 128us/sample - loss: 225182.2500\n",
      "Epoch 345/500\n",
      "1000/1000 [==============================] - 0s 127us/sample - loss: 225182.2656\n",
      "Epoch 346/500\n",
      "1000/1000 [==============================] - 0s 135us/sample - loss: 225182.2500\n",
      "Epoch 347/500\n",
      "1000/1000 [==============================] - 0s 127us/sample - loss: 225182.2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 348/500\n",
      "1000/1000 [==============================] - 0s 116us/sample - loss: 225182.2500\n",
      "Epoch 349/500\n",
      "1000/1000 [==============================] - 0s 119us/sample - loss: 225182.2656\n",
      "Epoch 350/500\n",
      "1000/1000 [==============================] - 0s 120us/sample - loss: 225182.2344\n",
      "Epoch 351/500\n",
      "1000/1000 [==============================] - 0s 118us/sample - loss: 225182.2344\n",
      "Epoch 352/500\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 225182.2500\n",
      "Epoch 353/500\n",
      "1000/1000 [==============================] - 0s 118us/sample - loss: 225182.2344\n",
      "Epoch 354/500\n",
      "1000/1000 [==============================] - 0s 119us/sample - loss: 225182.2344\n",
      "Epoch 355/500\n",
      "1000/1000 [==============================] - 0s 115us/sample - loss: 225182.2500\n",
      "Epoch 356/500\n",
      "1000/1000 [==============================] - 0s 121us/sample - loss: 225182.2500\n",
      "Epoch 357/500\n",
      "1000/1000 [==============================] - 0s 121us/sample - loss: 225182.2344\n",
      "Epoch 358/500\n",
      "1000/1000 [==============================] - 0s 117us/sample - loss: 225182.2656\n",
      "Epoch 359/500\n",
      "1000/1000 [==============================] - 0s 122us/sample - loss: 225182.2656\n",
      "Epoch 360/500\n",
      "1000/1000 [==============================] - 0s 118us/sample - loss: 225182.2500\n",
      "Epoch 361/500\n",
      "1000/1000 [==============================] - 0s 119us/sample - loss: 225182.2344\n",
      "Epoch 362/500\n",
      "1000/1000 [==============================] - 0s 119us/sample - loss: 225182.2344\n",
      "Epoch 363/500\n",
      "1000/1000 [==============================] - 0s 116us/sample - loss: 225182.2344\n",
      "Epoch 364/500\n",
      "1000/1000 [==============================] - 0s 117us/sample - loss: 225182.2500\n",
      "Epoch 365/500\n",
      "1000/1000 [==============================] - 0s 131us/sample - loss: 225182.2656\n",
      "Epoch 366/500\n",
      "1000/1000 [==============================] - 0s 120us/sample - loss: 225182.2344\n",
      "Epoch 367/500\n",
      "1000/1000 [==============================] - 0s 115us/sample - loss: 225182.2500\n",
      "Epoch 368/500\n",
      "1000/1000 [==============================] - 0s 119us/sample - loss: 225182.2500\n",
      "Epoch 369/500\n",
      "1000/1000 [==============================] - 0s 119us/sample - loss: 225182.2500\n",
      "Epoch 370/500\n",
      "1000/1000 [==============================] - 0s 116us/sample - loss: 225182.2344\n",
      "Epoch 371/500\n",
      "1000/1000 [==============================] - 0s 118us/sample - loss: 225182.2344\n",
      "Epoch 372/500\n",
      "1000/1000 [==============================] - 0s 117us/sample - loss: 225182.2344\n",
      "Epoch 373/500\n",
      "1000/1000 [==============================] - 0s 116us/sample - loss: 225182.2344\n",
      "Epoch 374/500\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 225182.2500\n",
      "Epoch 375/500\n",
      "1000/1000 [==============================] - 0s 119us/sample - loss: 225182.2500\n",
      "Epoch 376/500\n",
      "1000/1000 [==============================] - 0s 120us/sample - loss: 225182.2500\n",
      "Epoch 377/500\n",
      "1000/1000 [==============================] - 0s 121us/sample - loss: 225182.2500\n",
      "Epoch 378/500\n",
      "1000/1000 [==============================] - 0s 117us/sample - loss: 225182.2500\n",
      "Epoch 379/500\n",
      "1000/1000 [==============================] - 0s 115us/sample - loss: 225182.2656\n",
      "Epoch 380/500\n",
      "1000/1000 [==============================] - 0s 118us/sample - loss: 225182.2500\n",
      "Epoch 381/500\n",
      "1000/1000 [==============================] - 0s 117us/sample - loss: 225182.2500\n",
      "Epoch 382/500\n",
      "1000/1000 [==============================] - 0s 116us/sample - loss: 225182.2344\n",
      "Epoch 383/500\n",
      "1000/1000 [==============================] - 0s 116us/sample - loss: 225182.2500\n",
      "Epoch 384/500\n",
      "1000/1000 [==============================] - 0s 117us/sample - loss: 225182.2344\n",
      "Epoch 385/500\n",
      "1000/1000 [==============================] - 0s 121us/sample - loss: 225182.2344\n",
      "Epoch 386/500\n",
      "1000/1000 [==============================] - 0s 119us/sample - loss: 225182.2344\n",
      "Epoch 387/500\n",
      "1000/1000 [==============================] - 0s 118us/sample - loss: 225182.2500\n",
      "Epoch 388/500\n",
      "1000/1000 [==============================] - 0s 123us/sample - loss: 225182.2500\n",
      "Epoch 389/500\n",
      "1000/1000 [==============================] - 0s 116us/sample - loss: 225182.2188\n",
      "Epoch 390/500\n",
      "1000/1000 [==============================] - 0s 119us/sample - loss: 225182.2500\n",
      "Epoch 391/500\n",
      "1000/1000 [==============================] - 0s 114us/sample - loss: 225182.2344\n",
      "Epoch 392/500\n",
      "1000/1000 [==============================] - 0s 115us/sample - loss: 225182.2344\n",
      "Epoch 393/500\n",
      "1000/1000 [==============================] - 0s 125us/sample - loss: 225182.2344\n",
      "Epoch 394/500\n",
      "1000/1000 [==============================] - 0s 116us/sample - loss: 225182.2500\n",
      "Epoch 395/500\n",
      "1000/1000 [==============================] - 0s 119us/sample - loss: 225182.2344\n",
      "Epoch 396/500\n",
      "1000/1000 [==============================] - 0s 119us/sample - loss: 225182.2500\n",
      "Epoch 397/500\n",
      "1000/1000 [==============================] - 0s 113us/sample - loss: 225182.2500\n",
      "Epoch 398/500\n",
      "1000/1000 [==============================] - 0s 123us/sample - loss: 225182.2344\n",
      "Epoch 399/500\n",
      "1000/1000 [==============================] - 0s 115us/sample - loss: 225182.2344\n",
      "Epoch 400/500\n",
      "1000/1000 [==============================] - 0s 114us/sample - loss: 225182.2500\n",
      "Epoch 401/500\n",
      "1000/1000 [==============================] - 0s 117us/sample - loss: 225182.2500\n",
      "Epoch 402/500\n",
      "1000/1000 [==============================] - 0s 123us/sample - loss: 225182.2656\n",
      "Epoch 403/500\n",
      "1000/1000 [==============================] - 0s 131us/sample - loss: 225182.2344\n",
      "Epoch 404/500\n",
      "1000/1000 [==============================] - 0s 133us/sample - loss: 225182.2656\n",
      "Epoch 405/500\n",
      "1000/1000 [==============================] - 0s 128us/sample - loss: 225182.2500\n",
      "Epoch 406/500\n",
      "1000/1000 [==============================] - 0s 127us/sample - loss: 225182.2344\n",
      "Epoch 407/500\n",
      "1000/1000 [==============================] - 0s 135us/sample - loss: 225182.2344\n",
      "Epoch 408/500\n",
      "1000/1000 [==============================] - 0s 133us/sample - loss: 225182.2500\n",
      "Epoch 409/500\n",
      "1000/1000 [==============================] - 0s 132us/sample - loss: 225182.2344\n",
      "Epoch 410/500\n",
      "1000/1000 [==============================] - 0s 127us/sample - loss: 225182.2344\n",
      "Epoch 411/500\n",
      "1000/1000 [==============================] - 0s 133us/sample - loss: 225182.2500\n",
      "Epoch 412/500\n",
      "1000/1000 [==============================] - 0s 128us/sample - loss: 225182.2500\n",
      "Epoch 413/500\n",
      "1000/1000 [==============================] - 0s 132us/sample - loss: 225182.2344\n",
      "Epoch 414/500\n",
      "1000/1000 [==============================] - 0s 133us/sample - loss: 225182.2656\n",
      "Epoch 415/500\n",
      "1000/1000 [==============================] - 0s 138us/sample - loss: 225182.2344\n",
      "Epoch 416/500\n",
      "1000/1000 [==============================] - 0s 133us/sample - loss: 225182.2344\n",
      "Epoch 417/500\n",
      "1000/1000 [==============================] - 0s 124us/sample - loss: 225182.2344\n",
      "Epoch 418/500\n",
      "1000/1000 [==============================] - 0s 131us/sample - loss: 225182.2500\n",
      "Epoch 419/500\n",
      "1000/1000 [==============================] - 0s 127us/sample - loss: 225182.2344\n",
      "Epoch 420/500\n",
      "1000/1000 [==============================] - 0s 136us/sample - loss: 225182.2656\n",
      "Epoch 421/500\n",
      "1000/1000 [==============================] - 0s 132us/sample - loss: 225182.2500\n",
      "Epoch 422/500\n",
      "1000/1000 [==============================] - 0s 129us/sample - loss: 225182.2344\n",
      "Epoch 423/500\n",
      "1000/1000 [==============================] - 0s 134us/sample - loss: 225182.2500\n",
      "Epoch 424/500\n",
      "1000/1000 [==============================] - 0s 130us/sample - loss: 225182.2344\n",
      "Epoch 425/500\n",
      "1000/1000 [==============================] - 0s 131us/sample - loss: 225182.2656\n",
      "Epoch 426/500\n",
      "1000/1000 [==============================] - 0s 128us/sample - loss: 225182.2344\n",
      "Epoch 427/500\n",
      "1000/1000 [==============================] - 0s 126us/sample - loss: 225182.2344\n",
      "Epoch 428/500\n",
      "1000/1000 [==============================] - 0s 129us/sample - loss: 225182.2344\n",
      "Epoch 429/500\n",
      "1000/1000 [==============================] - 0s 131us/sample - loss: 225182.2656\n",
      "Epoch 430/500\n",
      "1000/1000 [==============================] - 0s 132us/sample - loss: 225182.2344\n",
      "Epoch 431/500\n",
      "1000/1000 [==============================] - 0s 140us/sample - loss: 225182.2344\n",
      "Epoch 432/500\n",
      "1000/1000 [==============================] - 0s 125us/sample - loss: 225182.2500\n",
      "Epoch 433/500\n",
      "1000/1000 [==============================] - 0s 136us/sample - loss: 225182.2500\n",
      "Epoch 434/500\n",
      "1000/1000 [==============================] - 0s 130us/sample - loss: 225182.2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 435/500\n",
      "1000/1000 [==============================] - 0s 134us/sample - loss: 225182.2344\n",
      "Epoch 436/500\n",
      "1000/1000 [==============================] - 0s 129us/sample - loss: 225182.2500\n",
      "Epoch 437/500\n",
      "1000/1000 [==============================] - 0s 127us/sample - loss: 225182.2188\n",
      "Epoch 438/500\n",
      "1000/1000 [==============================] - 0s 127us/sample - loss: 225182.2344\n",
      "Epoch 439/500\n",
      "1000/1000 [==============================] - 0s 130us/sample - loss: 225182.2500\n",
      "Epoch 440/500\n",
      "1000/1000 [==============================] - 0s 124us/sample - loss: 225182.2500\n",
      "Epoch 441/500\n",
      "1000/1000 [==============================] - 0s 128us/sample - loss: 225182.2344\n",
      "Epoch 442/500\n",
      "1000/1000 [==============================] - 0s 127us/sample - loss: 225182.2344\n",
      "Epoch 443/500\n",
      "1000/1000 [==============================] - 0s 124us/sample - loss: 225182.2344\n",
      "Epoch 444/500\n",
      "1000/1000 [==============================] - 0s 129us/sample - loss: 225182.2500\n",
      "Epoch 445/500\n",
      "1000/1000 [==============================] - 0s 131us/sample - loss: 225182.2500\n",
      "Epoch 446/500\n",
      "1000/1000 [==============================] - 0s 123us/sample - loss: 225182.2500\n",
      "Epoch 447/500\n",
      "1000/1000 [==============================] - 0s 125us/sample - loss: 225182.2344\n",
      "Epoch 448/500\n",
      "1000/1000 [==============================] - 0s 131us/sample - loss: 225182.2500\n",
      "Epoch 449/500\n",
      "1000/1000 [==============================] - 0s 123us/sample - loss: 225182.2344\n",
      "Epoch 450/500\n",
      "1000/1000 [==============================] - 0s 126us/sample - loss: 225182.2344\n",
      "Epoch 451/500\n",
      "1000/1000 [==============================] - 0s 130us/sample - loss: 225182.2656\n",
      "Epoch 452/500\n",
      "1000/1000 [==============================] - 0s 126us/sample - loss: 225182.2344\n",
      "Epoch 453/500\n",
      "1000/1000 [==============================] - 0s 117us/sample - loss: 225182.2500\n",
      "Epoch 454/500\n",
      "1000/1000 [==============================] - 0s 118us/sample - loss: 225182.2500\n",
      "Epoch 455/500\n",
      "1000/1000 [==============================] - 0s 120us/sample - loss: 225182.2344\n",
      "Epoch 456/500\n",
      "1000/1000 [==============================] - 0s 118us/sample - loss: 225182.2344\n",
      "Epoch 457/500\n",
      "1000/1000 [==============================] - 0s 119us/sample - loss: 225182.2344\n",
      "Epoch 458/500\n",
      "1000/1000 [==============================] - 0s 113us/sample - loss: 225182.2344\n",
      "Epoch 459/500\n",
      "1000/1000 [==============================] - 0s 120us/sample - loss: 225182.2500\n",
      "Epoch 460/500\n",
      "1000/1000 [==============================] - 0s 116us/sample - loss: 225182.2188\n",
      "Epoch 461/500\n",
      "1000/1000 [==============================] - 0s 116us/sample - loss: 225182.2656\n",
      "Epoch 462/500\n",
      "1000/1000 [==============================] - 0s 113us/sample - loss: 225182.2344\n",
      "Epoch 463/500\n",
      "1000/1000 [==============================] - 0s 119us/sample - loss: 225182.2500\n",
      "Epoch 464/500\n",
      "1000/1000 [==============================] - 0s 117us/sample - loss: 225182.2500\n",
      "Epoch 465/500\n",
      "1000/1000 [==============================] - 0s 113us/sample - loss: 225182.2344\n",
      "Epoch 466/500\n",
      "1000/1000 [==============================] - 0s 127us/sample - loss: 225182.2500\n",
      "Epoch 467/500\n",
      "1000/1000 [==============================] - 0s 117us/sample - loss: 225182.2344\n",
      "Epoch 468/500\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 225182.2500\n",
      "Epoch 469/500\n",
      "1000/1000 [==============================] - 0s 120us/sample - loss: 225182.2344\n",
      "Epoch 470/500\n",
      "1000/1000 [==============================] - 0s 116us/sample - loss: 225182.2500\n",
      "Epoch 471/500\n",
      "1000/1000 [==============================] - 0s 116us/sample - loss: 225182.2656\n",
      "Epoch 472/500\n",
      "1000/1000 [==============================] - 0s 117us/sample - loss: 225182.2344\n",
      "Epoch 473/500\n",
      "1000/1000 [==============================] - 0s 117us/sample - loss: 225182.2500\n",
      "Epoch 474/500\n",
      "1000/1000 [==============================] - 0s 114us/sample - loss: 225182.2344\n",
      "Epoch 475/500\n",
      "1000/1000 [==============================] - 0s 117us/sample - loss: 225182.2500\n",
      "Epoch 476/500\n",
      "1000/1000 [==============================] - 0s 118us/sample - loss: 225182.2344\n",
      "Epoch 477/500\n",
      "1000/1000 [==============================] - 0s 116us/sample - loss: 225182.2344\n",
      "Epoch 478/500\n",
      "1000/1000 [==============================] - 0s 118us/sample - loss: 225182.2344\n",
      "Epoch 479/500\n",
      "1000/1000 [==============================] - 0s 118us/sample - loss: 225182.2344\n",
      "Epoch 480/500\n",
      "1000/1000 [==============================] - 0s 118us/sample - loss: 225182.2500\n",
      "Epoch 481/500\n",
      "1000/1000 [==============================] - 0s 117us/sample - loss: 225182.2344\n",
      "Epoch 482/500\n",
      "1000/1000 [==============================] - 0s 118us/sample - loss: 225182.2500\n",
      "Epoch 483/500\n",
      "1000/1000 [==============================] - 0s 114us/sample - loss: 225182.2344\n",
      "Epoch 484/500\n",
      "1000/1000 [==============================] - 0s 120us/sample - loss: 225182.2344\n",
      "Epoch 485/500\n",
      "1000/1000 [==============================] - 0s 114us/sample - loss: 225182.2500\n",
      "Epoch 486/500\n",
      "1000/1000 [==============================] - 0s 115us/sample - loss: 225182.2656\n",
      "Epoch 487/500\n",
      "1000/1000 [==============================] - 0s 117us/sample - loss: 225182.2656\n",
      "Epoch 488/500\n",
      "1000/1000 [==============================] - 0s 121us/sample - loss: 225182.2188\n",
      "Epoch 489/500\n",
      "1000/1000 [==============================] - 0s 125us/sample - loss: 225182.2500\n",
      "Epoch 490/500\n",
      "1000/1000 [==============================] - 0s 117us/sample - loss: 225182.2500\n",
      "Epoch 491/500\n",
      "1000/1000 [==============================] - 0s 114us/sample - loss: 225182.2344\n",
      "Epoch 492/500\n",
      "1000/1000 [==============================] - 0s 119us/sample - loss: 225182.2344\n",
      "Epoch 493/500\n",
      "1000/1000 [==============================] - 0s 129us/sample - loss: 225182.2344\n",
      "Epoch 494/500\n",
      "1000/1000 [==============================] - 0s 119us/sample - loss: 225182.2500\n",
      "Epoch 495/500\n",
      "1000/1000 [==============================] - 0s 116us/sample - loss: 225182.2344\n",
      "Epoch 496/500\n",
      "1000/1000 [==============================] - 0s 119us/sample - loss: 225182.2344\n",
      "Epoch 497/500\n",
      "1000/1000 [==============================] - 0s 122us/sample - loss: 225182.2500\n",
      "Epoch 498/500\n",
      "1000/1000 [==============================] - 0s 118us/sample - loss: 225182.2500\n",
      "Epoch 499/500\n",
      "1000/1000 [==============================] - 0s 117us/sample - loss: 225182.2344\n",
      "Epoch 500/500\n",
      "1000/1000 [==============================] - 0s 119us/sample - loss: 225182.2344\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, GRU, Conv1D\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# RNN 모델을 생성 및 학습\n",
    "\n",
    "xInput = Input(batch_shape=(None, x_train.shape[1], x_train.shape[2]))\n",
    "x = LSTM(64, return_sequences = True)(xInput)\n",
    "x = LSTM(64)(x)\n",
    "x = Dense(64,activation = 'relu')(x)\n",
    "x = Dense(64,activation = 'relu')(x)\n",
    "xOutput = Dense(1, activation = 'linear')(x)\n",
    "\n",
    "\n",
    "model = Model(xInput, xOutput)\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "\n",
    "# 학습\n",
    "model.fit(x_train, y_train, epochs=500, batch_size=train_num,verbose=1)\n",
    "\n",
    "\n",
    " # 예측\n",
    "y_hat = model.predict(x_test, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예측 결과 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model.predict(x_test, batch_size=1)\n",
    "\n",
    "\n",
    "\n",
    "a_axis = np.arange(0, len(y_train))\n",
    "b_axis = np.arange(len(y_train), len(y_train) + len(y_hat))\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(a_axis, y_train.reshape(x_train,), '-')\n",
    "plt.plot(b_axis, y_hat.reshape(test_num,), '-', color='red', label='Predicted')\n",
    "plt.plot(b_axis, y_test.reshape(test_num,), '-', color='green', alpha=0.2, label='Actual')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
